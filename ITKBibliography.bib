@article{Herrmann2018,
abstract = {Background: Digital Imaging and Communications in Medicine (DICOM{\textregistered}) is the standard for the representation, storage, and communication of medical images and related information. A DICOM file format and communication protocol for pathology have been defined; however, adoption by vendors and in the field is pending. Here, we implemented the essential aspects of the standard and assessed its capabilities and limitations in a multisite, multivendor healthcare network. Methods: We selected relevant DICOM attributes, developed a program that extracts pixel data and pixel-related metadata, integrated patient and specimen-related metadata, populated and encoded DICOM attributes, and stored DICOM files. We generated the files using image data from four vendor-specific image file formats and clinical metadata from two departments with different laboratory information systems. We validated the generated DICOM files using recognized DICOM validation tools and measured encoding, storage, and access efficiency for three image compression methods. Finally, we evaluated storing, querying, and retrieving data over the web using existing DICOM archive software. Results: Whole slide image data can be encoded together with relevant patient and specimen-related metadata as DICOM objects. These objects can be accessed efficiently from files or through RESTful web services using existing software implementations. Performance measurements show that the choice of image compression method has a major impact on data access efficiency. For lossy compression, JPEG achieves the fastest compression/decompression rates. For lossless compression, JPEG-LS significantly outperforms JPEG 2000 with respect to data encoding and decoding speed. Conclusion: Implementation of DICOM allows efficient access to image data as well as associated metadata. By leveraging a wealth of existing infrastructure solutions, the use of DICOM facilitates enterprise integration and data exchange for digital pathology.},
author = {Herrmann, Markus D. and Clunie, David A. and Fedorov, Andriy and Doyle, Sean W. and Pieper, Steven and Klepeis, Veronica and Le, Long P. and Mutter, George L. and Milstone, David S. and Schultz, Thomas J. and Kikinis, Ron and Kotecha, Gopal K. and Hwang, David H. and Andriole, Katherine P. and {John Iafrate}, A. and Brink, James A. and Boland, Giles W. and Dreyer, Keith J. and Michalski, Mark and Golden, Jeffrey A. and Louis, David N. and Lennerz, Jochen K.},
doi = {10.4103/jpi.jpi_42_18},
issn = {21533539},
journal = {Journal of Pathology Informatics},
keywords = {Computational pathology,DICOMweb,Image compression,Slide scanning,Whole slide imaging},
month = {jan},
number = {1},
pmid = {30533276},
publisher = {Wolters Kluwer Medknow Publications},
title = {{Implementing the DICOM standard for digital pathology}},
volume = {9},
year = {2018}
}
@article{Malkasian2018,
abstract = {Background: As combined morphological and physiological assessment of coronary artery disease (CAD) is necessary to reliably resolve CAD severity, the objective of this study was to validate an automated minimum-cost path assignment (MCP) technique which enables accurate, vessel-specific assignment of the left (LCA) and right (RCA) coronary perfusion territories using computed tomography (CT) angiography data for both left and right ventricles. Methods: Six swine were used to validate the MCP technique. In each swine, a dynamic acquisition comprised of twenty consecutive volume scans was acquired with a 320-slice CT scanner following peripheral injection of contrast material. From this acquisition the MCP technique was used to automatically assign LCA and RCA perfusion territories for the left and right ventricles, independently. Each animal underwent another dynamic CT acquisition following direct injection of contrast material into the LCA or RCA. Using this acquisition, reference standard LCA and RCA perfusion territories were isolated from the myocardial blush. The accuracy of the MCP technique was evaluated by quantitatively comparing the MCP-derived LCA and RCA perfusion territories to these reference standard territories. Results: All MCP perfusion territory masses (MassMCP) and all reference standard perfusion territory masses (MassRS) in the left ventricle were related by MassMCP = 0.99MassRS+0.35 g (r = 1.00). MassMCP and MassRS in the right ventricle were related by MassMCP = 0.94MassRS+0.39 g (r = 0.96). Conclusion: The MCP technique was validated in a swine animal model and has the potential to be used for accurate, vessel-specific assignment of LCA and RCA perfusion territories in both the left and right ventricular myocardium using CT angiography data. In order to provide a comprehensive morphological and physiological cardiac imaging datasets, the minimum-cost path assignment (MCP) method has been validated, using a swine animal model and computed tomography (CT) imaging. MCP has been shown to accurately quantify left and right coronary artery perfusion territories in the left ventricle, right ventricle and whole heart. The MCP technique provides clinicians and researchers in cardiovascular imaging with a means to accurately and automatically determine coronary-specific perfusion territories in the left and right heart, and could also be used to assess myocardium at-risk distal to a stenosis.},
author = {Malkasian, Shant and Hubbard, Logan and Dertli, Brian and Kwon, Jungnam and Molloi, Sabee},
doi = {10.1016/j.jcct.2018.06.006},
issn = {1876861X},
journal = {Journal of Cardiovascular Computed Tomography},
keywords = {Angiography,Cardiovascular disease,Computerized tomography,Coronary artery disease,Imaging,Myocardium},
month = {sep},
number = {5},
pages = {425--435},
publisher = {Elsevier Inc.},
title = {{Quantification of vessel-specific coronary perfusion territories using minimum-cost path assignment and computed tomography angiography: Validation in a swine model}},
volume = {12},
year = {2018}
}
@article{Khanal2017,
abstract = {This paper presents a simulator tool that can simulate large databases of visually realistic longitudinal MRIs with known volume changes. The simulator is based on a previously proposed biophysical model of brain deformation due to atrophy in AD. In this work, we propose a novel way of reproducing realistic intensity variation in longitudinal brain MRIs, which is inspired by an approach used for the generation of synthetic cardiac sequence images. This approach combines a deformation field obtained from the biophysical model with a deformation field obtained by a non-rigid registration of two images. The combined deformation field is then used to simulate a new image with specified atrophy from the first image, but with the intensity characteristics of the second image. This allows to generate the realistic variations present in real longitudinal time-series of images, such as the independence of noise between two acquisitions and the potential presence of variable acquisition artifacts. Various options available in the simulator software are briefly explained in this paper. In addition, the software is released as an open-source repository. The availability of the software allows researchers to produce tailored databases of images with ground truth volume changes; we believe this will help developing more robust brain morphometry tools. Additionally, we believe that the scientific community can also use the software to further experiment with the proposed model, and add more complex models of brain deformation and atrophy generation.},
author = {Khanal, Bishesh and Ayache, Nicholas and Pennec, Xavier},
doi = {10.3389/fnins.2017.00132},
issn = {1662453X},
journal = {Frontiers in Neuroscience},
keywords = {Biomechanical simulation,Biophysical modeling,Neurodegeneration,Simulated database,Synthetic images,Synthetic longitudinal MRIs},
month = {mar},
number = {MAR},
publisher = {Frontiers Research Foundation},
title = {{Simulating longitudinal brain MRIs with known volume changes and realistic variations in image intensity}},
volume = {11},
year = {2017}
}
@article{Hadj-Hamou2016,
abstract = {We propose and detail a deformation-based morphometry computational framework, called Longitudinal Log-Demons Framework (LLDF), to estimate the longitudinal brain deformations from image data series, transport them in a common space and perform statistical group-wise analyses. It is based on freely available software and tools, and consists of three main steps: (i) Pre-processing, (ii) Position correction, and (iii) Non-linear deformation analysis. It is based on the LCC log-Demons non-linear symmetric diffeomorphic registration algorithm with an additional modulation of the similarity term using a confidence mask to increase the robustness with respect to brain boundary intensity artifacts. The pipeline is exemplified on the longitudinal Open Access Series of Imaging Studies (OASIS) database and all the parameters values are given so that the study can be reproduced. We investigate the group-wise differences between the patients with Alzheimer's disease and the healthy control group, and show that the proposed pipeline increases the sensitivity with no decrease in the specificity of the statistical study done on the longitudinal deformations.},
author = {Hadj-Hamou, Mehdi and Lorenzi, Marco and Ayache, Nicholas and Pennec, Xavier},
doi = {10.3389/fnins.2016.00236},
issn = {1662453X},
journal = {Frontiers in Neuroscience},
keywords = {Deformation-based morphometry,Diffeomorphism parametrized by stationary velocity fields,Longitudinal study,Non-linear registration,Reproducible research,Statistical analysis},
month = {jun},
number = {JUN},
publisher = {Frontiers Research Foundation},
title = {{Longitudinal analysis of image time series with diffeomorphic deformations: A computational framework based on stationary velocity fields}},
volume = {10},
year = {2016}
}
@article{Herrmann2018a,
abstract = {Background: Digital Imaging and Communications in Medicine (DICOM{\textregistered}) is the standard for the representation, storage, and communication of medical images and related information. A DICOM file format and communication protocol for pathology have been defined; however, adoption by vendors and in the field is pending. Here, we implemented the essential aspects of the standard and assessed its capabilities and limitations in a multisite, multivendor healthcare network. Methods: We selected relevant DICOM attributes, developed a program that extracts pixel data and pixel-related metadata, integrated patient and specimen-related metadata, populated and encoded DICOM attributes, and stored DICOM files. We generated the files using image data from four vendor-specific image file formats and clinical metadata from two departments with different laboratory information systems. We validated the generated DICOM files using recognized DICOM validation tools and measured encoding, storage, and access efficiency for three image compression methods. Finally, we evaluated storing, querying, and retrieving data over the web using existing DICOM archive software. Results: Whole slide image data can be encoded together with relevant patient and specimen-related metadata as DICOM objects. These objects can be accessed efficiently from files or through RESTful web services using existing software implementations. Performance measurements show that the choice of image compression method has a major impact on data access efficiency. For lossy compression, JPEG achieves the fastest compression/decompression rates. For lossless compression, JPEG-LS significantly outperforms JPEG 2000 with respect to data encoding and decoding speed. Conclusion: Implementation of DICOM allows efficient access to image data as well as associated metadata. By leveraging a wealth of existing infrastructure solutions, the use of DICOM facilitates enterprise integration and data exchange for digital pathology.},
author = {Herrmann, Markus D. and Clunie, David A. and Fedorov, Andriy and Doyle, Sean W. and Pieper, Steven and Klepeis, Veronica and Le, Long P. and Mutter, George L. and Milstone, David S. and Schultz, Thomas J. and Kikinis, Ron and Kotecha, Gopal K. and Hwang, David H. and Andriole, Katherine P. and {John Iafrate}, A. and Brink, James A. and Boland, Giles W. and Dreyer, Keith J. and Michalski, Mark and Golden, Jeffrey A. and Louis, David N. and Lennerz, Jochen K.},
doi = {10.4103/jpi.jpi_42_18},
issn = {21533539},
journal = {Journal of Pathology Informatics},
keywords = {Computational pathology,DICOMweb,Image compression,Slide scanning,Whole slide imaging},
month = {jan},
number = {1},
pmid = {30533276},
publisher = {Wolters Kluwer Medknow Publications},
title = {{Implementing the DICOM standard for digital pathology}},
volume = {9},
year = {2018}
}
@article{Li2018,
abstract = {Purpose: The purpose of this study was to enhance the deformation range of demons-based deformable image registration (DIR) for large respiration-induced organ motion in the reconstruction of time-resolved four-dimensional magnetic resonance imaging (TR-4DMRI) for multi-breath motion simulation. Methods: A demons-based DIR algorithm was modified to enhance the deformation range for TR-4DMRI reconstruction using the super-resolution approach. A pseudo demons force was introduced to accelerate the coarse deformation in a multi-resolution (n = 3) DIR approach. The intensity gradient of a voxel was applied to its neighboring (5 × 5 × 5) voxels with a weight of Gaussian probability profile ($\sigma$ = 1 voxel) to extend the demons force, especially on those voxels that have little intensity gradience but high-intensity difference. A digital 4DMRI phantom with 3–8 cm diaphragmatic motions was used for DIR comparison. Six volunteers were scanned with two high-resolution (highR: 2 × 2 × 2 mm3) breath-hold (BH) 3DMR images at full inhalation (BHI) and full exhalation (BHE) and low-resolution (lowR: 5 × 5 × 5 mm3) free-breathing (FB) 3DMR cine images (2 Hz) under an IRB-approved protocol. A cross-consistency check (CCC) (BHI→FB←BHE), with voxel intensity correlation (VIC) and inverse consistency error (ICE), was introduced for cross-verification of TR-4DMRI reconstruction. Results: Using the digital phantom, the maximum deformable magnitude is doubled using the modified DIR from 3 to 6 cm at the diaphragm. In six human subjects, the first 15-iteration DIR using the pseudo force deforms 200 ± 150{\%} more than the original force, and succeeds in all 12 cases, whereas the original demons-based DIR failed in 67{\%} of tested cases. Using the pseudo force, high VIC ({\textgreater}0.9) and small ICE (1.6 ± 0.6 mm) values are observed for DIR of BHI{\&}BHE, BHI→FB, and BHE→FB. The CCC identifies four questionable cases, in which two cases need further DIR refinement, without missing true negative. Conclusions: The introduction of a pseudo demons force enhances the largest deformation magnitude up to 6 cm. The cross-consistency check ensures the quality of TR-4DMRI reconstruction. Further investigation is ongoing to fully characterize TR-4DMRI for potential multi-breathing-cycle radiotherapy simulation.},
author = {Li, Guang and Sun, August and Nie, Xingyu and Moody, Jason and Huang, Kirk and Zhang, Shirong and Sharma, Satyam and Deasy, Joseph},
doi = {10.1002/mp.13179},
issn = {00942405},
journal = {Medical Physics},
keywords = {deformable image registration (DIR),image-guided radiotherapy (IGRT),multi-breath motion assessment,time-resolved four-dimensional magnetic resonance image (TR-4DMRI)},
month = {nov},
number = {11},
pages = {5197--5207},
publisher = {John Wiley and Sons Ltd.},
title = {{Introduction of a pseudo demons force to enhance deformation range for robust reconstruction of super-resolution time-resolved 4DMRI}},
volume = {45},
year = {2018}
}
@article{Malkasian2018a,
abstract = {Background: As combined morphological and physiological assessment of coronary artery disease (CAD) is necessary to reliably resolve CAD severity, the objective of this study was to validate an automated minimum-cost path assignment (MCP) technique which enables accurate, vessel-specific assignment of the left (LCA) and right (RCA) coronary perfusion territories using computed tomography (CT) angiography data for both left and right ventricles. Methods: Six swine were used to validate the MCP technique. In each swine, a dynamic acquisition comprised of twenty consecutive volume scans was acquired with a 320-slice CT scanner following peripheral injection of contrast material. From this acquisition the MCP technique was used to automatically assign LCA and RCA perfusion territories for the left and right ventricles, independently. Each animal underwent another dynamic CT acquisition following direct injection of contrast material into the LCA or RCA. Using this acquisition, reference standard LCA and RCA perfusion territories were isolated from the myocardial blush. The accuracy of the MCP technique was evaluated by quantitatively comparing the MCP-derived LCA and RCA perfusion territories to these reference standard territories. Results: All MCP perfusion territory masses (MassMCP) and all reference standard perfusion territory masses (MassRS) in the left ventricle were related by MassMCP = 0.99MassRS+0.35 g (r = 1.00). MassMCP and MassRS in the right ventricle were related by MassMCP = 0.94MassRS+0.39 g (r = 0.96). Conclusion: The MCP technique was validated in a swine animal model and has the potential to be used for accurate, vessel-specific assignment of LCA and RCA perfusion territories in both the left and right ventricular myocardium using CT angiography data. In order to provide a comprehensive morphological and physiological cardiac imaging datasets, the minimum-cost path assignment (MCP) method has been validated, using a swine animal model and computed tomography (CT) imaging. MCP has been shown to accurately quantify left and right coronary artery perfusion territories in the left ventricle, right ventricle and whole heart. The MCP technique provides clinicians and researchers in cardiovascular imaging with a means to accurately and automatically determine coronary-specific perfusion territories in the left and right heart, and could also be used to assess myocardium at-risk distal to a stenosis.},
author = {Malkasian, Shant and Hubbard, Logan and Dertli, Brian and Kwon, Jungnam and Molloi, Sabee},
doi = {10.1016/j.jcct.2018.06.006},
issn = {1876861X},
journal = {Journal of Cardiovascular Computed Tomography},
keywords = {Angiography,Cardiovascular disease,Computerized tomography,Coronary artery disease,Imaging,Myocardium},
month = {sep},
number = {5},
pages = {425--435},
publisher = {Elsevier Inc.},
title = {{Quantification of vessel-specific coronary perfusion territories using minimum-cost path assignment and computed tomography angiography: Validation in a swine model}},
volume = {12},
year = {2018}
}
@article{Khanal2017a,
abstract = {This paper presents a simulator tool that can simulate large databases of visually realistic longitudinal MRIs with known volume changes. The simulator is based on a previously proposed biophysical model of brain deformation due to atrophy in AD. In this work, we propose a novel way of reproducing realistic intensity variation in longitudinal brain MRIs, which is inspired by an approach used for the generation of synthetic cardiac sequence images. This approach combines a deformation field obtained from the biophysical model with a deformation field obtained by a non-rigid registration of two images. The combined deformation field is then used to simulate a new image with specified atrophy from the first image, but with the intensity characteristics of the second image. This allows to generate the realistic variations present in real longitudinal time-series of images, such as the independence of noise between two acquisitions and the potential presence of variable acquisition artifacts. Various options available in the simulator software are briefly explained in this paper. In addition, the software is released as an open-source repository. The availability of the software allows researchers to produce tailored databases of images with ground truth volume changes; we believe this will help developing more robust brain morphometry tools. Additionally, we believe that the scientific community can also use the software to further experiment with the proposed model, and add more complex models of brain deformation and atrophy generation.},
author = {Khanal, Bishesh and Ayache, Nicholas and Pennec, Xavier},
doi = {10.3389/fnins.2017.00132},
issn = {1662453X},
journal = {Frontiers in Neuroscience},
keywords = {Biomechanical simulation,Biophysical modeling,Neurodegeneration,Simulated database,Synthetic images,Synthetic longitudinal MRIs},
month = {mar},
number = {MAR},
publisher = {Frontiers Research Foundation},
title = {{Simulating longitudinal brain MRIs with known volume changes and realistic variations in image intensity}},
volume = {11},
year = {2017}
}
@article{Klemm2017,
abstract = {Purpose: Due to rapid developments in the research areas of medical imaging, medical image processing and robotics, computer-assisted interventions (CAI) are becoming an integral part of modern patient care. From a software engineering point of view, these systems are highly complex and research can benefit greatly from reusing software components. This is supported by a number of open-source toolkits for medical imaging and CAI such as the medical imaging interaction toolkit (MITK), the public software library for ultrasound imaging research (PLUS) and 3D Slicer. An independent inter-toolkit communication such as the open image-guided therapy link (OpenIGTLink) can be used to combine the advantages of these toolkits and enable an easier realization of a clinical CAI workflow. Methods: MITK-OpenIGTLink is presented as a network interface within MITK that allows easy to use, asynchronous two-way messaging between MITK and clinical devices or other toolkits. Performance and interoperability tests with MITK-OpenIGTLink were carried out considering the whole CAI workflow from data acquisition over processing to visualization. Results: We present how MITK-OpenIGTLink can be applied in different usage scenarios. In performance tests, tracking data were transmitted with a frame rate of up to 1000 Hz and a latency of 2.81 ms. Transmission of images with typical ultrasound (US) and greyscale high-definition (HD) resolutions of 640 × 480 and 1920 × 1080 is possible at up to 512 and 128 Hz, respectively. Conclusion: With the integration of OpenIGTLink into MITK, this protocol is now supported by all established open-source toolkits in the field. This eases interoperability between MITK and toolkits such as PLUS or 3D Slicer and facilitates cross-toolkit research collaborations. MITK and its submodule MITK-OpenIGTLink are provided open source under a BSD-style licence (http://mitk.org).},
author = {Klemm, Martin and Kirchner, Thomas and Gr{\"{o}}hl, Janek and Cheray, Dominique and Nolden, Marco and Seitel, Alexander and Hoppe, Harald and Maier-Hein, Lena and Franz, Alfred M.},
doi = {10.1007/s11548-016-1488-y},
issn = {18616429},
journal = {International Journal of Computer Assisted Radiology and Surgery},
keywords = {Computer-assisted interventions,Image-guided therapy,Interoperability,MITK,OpenIGTLink,Ultrasound},
month = {mar},
number = {3},
pages = {351--361},
publisher = {Springer Verlag},
title = {{MITK-OpenIGTLink for combining open-source toolkits in real-time computer-assisted interventions}},
volume = {12},
year = {2017}
}
@article{Hadj-Hamou2016a,
abstract = {We propose and detail a deformation-based morphometry computational framework, called Longitudinal Log-Demons Framework (LLDF), to estimate the longitudinal brain deformations from image data series, transport them in a common space and perform statistical group-wise analyses. It is based on freely available software and tools, and consists of three main steps: (i) Pre-processing, (ii) Position correction, and (iii) Non-linear deformation analysis. It is based on the LCC log-Demons non-linear symmetric diffeomorphic registration algorithm with an additional modulation of the similarity term using a confidence mask to increase the robustness with respect to brain boundary intensity artifacts. The pipeline is exemplified on the longitudinal Open Access Series of Imaging Studies (OASIS) database and all the parameters values are given so that the study can be reproduced. We investigate the group-wise differences between the patients with Alzheimer's disease and the healthy control group, and show that the proposed pipeline increases the sensitivity with no decrease in the specificity of the statistical study done on the longitudinal deformations.},
author = {Hadj-Hamou, Mehdi and Lorenzi, Marco and Ayache, Nicholas and Pennec, Xavier},
doi = {10.3389/fnins.2016.00236},
issn = {1662453X},
journal = {Frontiers in Neuroscience},
keywords = {Deformation-based morphometry,Diffeomorphism parametrized by stationary velocity fields,Longitudinal study,Non-linear registration,Reproducible research,Statistical analysis},
month = {jun},
number = {JUN},
publisher = {Frontiers Research Foundation},
title = {{Longitudinal analysis of image time series with diffeomorphic deformations: A computational framework based on stationary velocity fields}},
volume = {10},
year = {2016}
}
@misc{Avants2015,
author = {Avants, Brian B. and Johnson, Hans J. and Tustison, Nicholas J.},
booktitle = {Frontiers in Neuroinformatics},
doi = {10.3389/fninf.2015.00005},
issn = {16625196},
keywords = {C++,ITK,Open source,Registration,Segmentation},
month = {mar},
number = {MAR},
publisher = {Frontiers Research Foundation},
title = {{Neuroinformatics and the the insight toolkit}},
volume = {9},
year = {2015}
}
@inproceedings{Yatabe2017,
author = {Yatabe, Marilia and Ruellas, Antonio and Gomes, Liliane and Macron, Lucie and Lopinto, Julia and Paniagua, Beatriz and Budin, Francois and Cevidanes, Lucia},
booktitle = {2017 IADR/AADR/CADR General Session (San Francisco, California) },
mendeley-groups = {PersonalBibliography},
title = {{Comparative Study of Three Methods to Compute 3D Craniofacial Angular Measurements}},
url = {https://iadr.abstractarchives.com/abstract/17iags-2636290/comparative-study-of-three-methods-to-compute-3d-craniofacial-angular-measurements},
year = {2017}
}
@misc{Avants2015a,
author = {Avants, Brian B. and Johnson, Hans J. and Tustison, Nicholas J.},
booktitle = {Frontiers in Neuroinformatics},
doi = {10.3389/fninf.2015.00005},
issn = {16625196},
keywords = {C++,ITK,Open source,Registration,Segmentation},
month = {mar},
number = {MAR},
publisher = {Frontiers Research Foundation},
title = {{Neuroinformatics and the the insight toolkit}},
volume = {9},
year = {2015}
}
@article{,
pmid = {25859213},
title = {{(No Title)}}
}
@article{Sebille2019,
author = {S{\'{e}}bille, Sophie B. and Rolland, Anne‐Sophie and Faillot, Matthieu and Perez‐Garcia, Fernando and Colomb‐Clerc, Antoine and Lau, Brian and Dumas, Sylvie and Vidal, Sara Fernandez and Welter, Marie‐Laure and Francois, Chantal and Bardinet, Eric and Karachi, Carine},
doi = {10.1002/mds.27578},
issn = {0885-3185},
journal = {Movement Disorders},
month = {feb},
number = {2},
pages = {218--227},
title = {{Normal and pathological neuronal distribution of the human mesencephalic locomotor region}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mds.27578},
volume = {34},
year = {2019}
}
@article{Vigneault2018,
abstract = {Recent improvements in cardiac computed tomography (CCT) allow for whole-heart functional studies to be acquired at low radiation dose ({\textless}2mSv) and high-temporal resolution ({\textless}100ms) in a single heart beat. Although the extraction of regional functional information from these images is of great clinical interest, there is a paucity of research into the quantification of regional function from CCT, contrasting with the large body of work in echocardiography and cardiac MR. Here we present the Simultaneous Subdivision Surface Registration (SiSSR) method: a fast, semi-automated image analysis pipeline for quantifying regional function from contrast-enhanced CCT. For each of thirteen adult male canines, we construct an anatomical reference mesh representing the left ventricular (LV) endocardium, obviating the need for a template mesh to be manually sculpted and initialized. We treat this generated mesh as a Loop subdivision surface, and adapt a technique previously described in the context of 3-D echocardiography to register these surfaces to the endocardium efficiently across all cardiac frames simultaneously. Although previous work performs the registration at a single resolution, we observe that subdivision surfaces naturally suggest a multiresolution approach, leading to faster convergence and avoiding local minima. We additionally make two notable changes to the cost function of the optimization, explicitly encouraging plausible biological motion and high mesh quality. Finally, we calculate an accepted functional metric for CCT from the registered surfaces, and compare our results to an alternate state-of-the-art CCT method.},
author = {Vigneault, Davis M. and Pourmorteza, Amir and Thomas, Marvin L. and Bluemke, David A. and Noble, J. Alison},
doi = {10.1016/j.media.2018.03.009},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Cardiac computed tomography,Loop subdivision surface,Personalized cardiac mesh generation,Regional cardiac function},
month = {may},
pages = {215--228},
publisher = {Elsevier B.V.},
title = {{SiSSR: Simultaneous subdivision surface registration for the quantification of cardiac function from computed tomography in canines}},
volume = {46},
year = {2018}
}
@article{Looney2018,
abstract = {We present a new technique to fully automate the segmentation of an organ from 3D ultrasound (3D-US) volumes, using the placenta as the target organ. Image analysis tools to estimate organ volume do exist but are too time consuming and operator dependant. Fully automating the segmentation process would potentially allow the use of placental volume to screen for increased risk of pregnancy complications. The placenta was segmented from 2,393 first trimester 3D-US volumes using a semiautomated technique. This was quality controlled by three operators to produce the "ground-truth" data set. A fully convolutional neural network (OxNNet) was trained using this ground-truth data set to automatically segment the placenta. OxNNet delivered state-of-the-art automatic segmentation. The effect of training set size on the performance of OxNNet demonstrated the need for large data sets. The clinical utility of placental volume was tested by looking at predictions of small-for-gestational-age babies at term. The receiver-operating characteristics curves demonstrated almost identical results between OxNNet and the ground-truth). Our results demonstrated good similarity to the ground-truth and almost identical clinical results for the prediction of SGA.},
author = {Looney, P{\'{a}}draig and Stevenson, Gordon N. and Nicolaides, Kypros H. and Plasencia, Walter and Molloholli, Malid and Natsis, Stavros and Collins, Sally L.},
doi = {10.1172/jci.insight.120178},
file = {:Users/bpaniagua/Library/Application Support/Mendeley Desktop/Downloaded/Looney et al. - 2018 - Fully automated, real-time 3D ultrasound segmentation to estimate first trimester placental volume using deep lea.pdf:pdf},
issn = {23793708},
journal = {JCI insight},
keywords = {Diagnostic imaging,Obstetrics/gynecology,Reproductive Biology},
month = {jun},
number = {11},
publisher = {NLM (Medline)},
title = {{Fully automated, real-time 3D ultrasound segmentation to estimate first trimester placental volume using deep learning}},
volume = {3},
year = {2018}
}
@article{Hernandez-Cerdan2018,
author = {Hernandez-Cerdan, Pablo and Mansel, Bradley W. and Leis, Andrew and Lundin, Leif and Williams, Martin A.K.},
doi = {10.1021/acs.biomac.7b01773},
issn = {1525-7797},
journal = {Biomacromolecules},
month = {mar},
number = {3},
pages = {989--995},
title = {{Structural Analysis of Polysaccharide Networks by Transmission Electron Microscopy: Comparison with Small-Angle X-ray Scattering}},
url = {https://pubs.acs.org/doi/10.1021/acs.biomac.7b01773},
volume = {19},
year = {2018}
}
@article{Belmonte2018,
abstract = {Spatial and spatio-temporal model checking techniques have a wide range of application domains, among which large scale distributed systems and signal and image analysis. We explore a new domain, namely (semi-)automatic contouring in Medical Imaging, introducing the tool VoxLogicA which merges the state-of-the-art library of computational imaging algorithms ITK with the unique combination of declarative specification and optimised execution provided by spatial logic model checking. The result is a rapid, logic based analysis development methodology. The analysis of an existing benchmark of medical images for segmentation of brain tumours shows that simple VoxLogicA analysis can reach state-of-the-art accuracy, competing with best-in-class algorithms, with the advantage of explainability and replicability. Furthermore, due to a two-orders-of-magnitude speedup compared to the existing general-purpose spatio-temporal model checker topochecker, VoxLogicA enables interactive development of analysis of 3D medical images, which can greatly facilitate the work of professionals in this domain.},
archivePrefix = {arXiv},
arxivId = {1811.05677},
author = {Belmonte, Gina and Ciancia, Vincenzo and Latella, Diego and Massink, Mieke},
eprint = {1811.05677},
file = {:Users/bpaniagua/Library/Application Support/Mendeley Desktop/Downloaded/Belmonte et al. - 2018 - VoxLogicA a Spatial Model Checker for Declarative Image Analysis (Extended Version).pdf:pdf},
month = {nov},
title = {{VoxLogicA: a Spatial Model Checker for Declarative Image Analysis (Extended Version)}},
url = {http://arxiv.org/abs/1811.05677},
year = {2018}
}
@misc{,
title = {{Welcome to Orfeo ToolBox! — Orfeo ToolBox 7.0.0 documentation}},
url = {https://www.orfeo-toolbox.org/CookBook/},
urldate = {2020-02-03}
}
@article{Oliveira2015,
abstract = {Objective. The aim of the present study was to develop a fully-automated computational solution for computer-aided diagnosis in Parkinson syndrome based on [123I]FP-CIT single photon emission computed tomography (SPECT) images. Approach. A dataset of 654 [123I]FP-CIT SPECT brain images from the Parkinson's Progression Markers Initiative were used. Of these, 445 images were of patients with Parkinson's disease at an early stage and the remainder formed a control group. The images were pre-processed using automated template-based registration followed by the computation of the binding potential at a voxel level. Then, the binding potential images were used for classification, based on the voxel-as-feature approach and using the support vector machines paradigm. Main results. The obtained estimated classification accuracy was 97.86{\%}, the sensitivity was 97.75{\%} and the specificity 98.09{\%}. Significance. The achieved classification accuracy was very high and, in fact, higher than accuracies found in previous studies reported in the literature. In addition, results were obtained on a large dataset of early Parkinson's disease subjects. In summation, the information provided by the developed computational solution potentially supports clinical decision-making in nuclear medicine, using important additional information beyond the commonly used uptake ratios and respective statistical comparisons. (ClinicalTrials.gov Identifier: NCT01141023)},
author = {Oliveira, Francisco P.M. and Castelo-Branco, Miguel},
doi = {10.1088/1741-2560/12/2/026008},
issn = {17412552},
journal = {Journal of Neural Engineering},
keywords = {DaTSCAN,automated image analysis,binding potential,classification},
month = {apr},
number = {2},
publisher = {Institute of Physics Publishing},
title = {{Computer-aided diagnosis of Parkinson's disease based on [123I]FP-CIT SPECT binding potential images, using the voxels-as-features approach and support vector machines}},
volume = {12},
year = {2015}
}
@inproceedings{Hernandez-Cerdan2019,
author = {Hernandez-Cerdan, Pablo and Paniagua, Beatriz and Prothero, Jack and Marron, James S. and Livingston, Eric and Bateman, Ted and McCormick, Matthew M.},
doi = {10.1117/12.2513007},
isbn = {9781510625532},
issn = {16057422},
month = {mar},
pages = {40},
publisher = {SPIE-Intl Soc Optical Eng},
title = {{Methods for quantitative characterization of bone injury from computed-tomography images}},
year = {2019}
}
@inproceedings{Paniagua2018,
abstract = {Studies show that cracked teeth are the third most common cause for tooth loss in industrialized countries. If detected early and accurately, patients can retain their teeth for a longer time. Most cracks are not detected early because of the discontinuous symptoms and lack of good diagnostic tools. Currently used imaging modalities like Cone Beam Computed Tomography (CBCT) and intraoral radiography often have low sensitivity and do not show cracks clearly. This paper introduces a novel method that can detect, quantify, and localize cracks automatically in high resolution CBCT (hr-CBCT) scans of teeth using steerable wavelets and learning methods. These initial results were created using hr-CBCT scans of a set of healthy teeth and of teeth with simulated longitudinal cracks. The cracks were simulated using multiple orientations. The crack detection was trained on the most significant wavelet coefficients at each scale using a bagged classifier of Support Vector Machines. Our results show high discriminative specificity and sensitivity of this method. The framework aims to be automatic, reproducible, and open-source. Future work will focus on the clinical validation of the proposed techniques on different types of cracks ex-vivo. We believe that this work will ultimately lead to improved tracking and detection of cracks allowing for longer lasting healthy teeth.},
author = {Paniagua, Beatriz and Shah, Hina and Hernandez-Cerdan, Pablo and Budin, Francois and Chittajallu, Deepak and Walter, Rick and Mol, Andre and Khan, Asma and Vimort, Jean-Baptiste},
booktitle = {Medical Imaging 2018: Biomedical Applications in Molecular, Structural, and Functional Imaging},
doi = {10.1117/12.2293603},
editor = {Gimi, Barjor and Krol, Andrzej},
isbn = {9781510616455},
keywords = {Cracked teeth,Isotropic Wavelets,Machine Learning,Support Vector Machine},
mendeley-groups = {PersonalBibliography},
month = {mar},
pages = {55},
publisher = {SPIE},
title = {{Automatic quantification framework to detect cracks in teeth}},
url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10578/2293603/Automatic-quantification-framework-to-detect-cracks-in-teeth/10.1117/12.2293603.full},
volume = {10578},
year = {2018}
}
@inproceedings{Paniagua2019,
author = {Paniagua, Beatriz and Prothero, Jack and Vimort, Jean-Baptiste and Ruellas, Antonio Carlos O. and Marron, James S. and Cevidanes, Lucia and Benavides, Erika and McCormick, Matthew M. and Hernandez-Cerdan, Pablo},
doi = {10.1117/12.2507978},
isbn = {9781510625532},
issn = {16057422},
month = {mar},
pages = {42},
publisher = {SPIE-Intl Soc Optical Eng},
title = {{Advanced statistical analysis to classify high dimensionality textural probability-distribution matrices}},
year = {2019}
}
@inproceedings{Fishbaugh2018,
author = {Fishbaugh, James and Pascal, Laura and Fischer, Luke and Nguyen, Tung and Boen, Celso and Goncalves, Joao and Gerig, Guido and Paniagua, Beatriz},
booktitle = {2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)},
doi = {10.1109/ISBI.2018.8363742},
isbn = {978-1-5386-3636-7},
mendeley-groups = {PersonalBibliography},
month = {apr},
pages = {1010--1013},
publisher = {IEEE},
title = {{Estimating shape correspondence for populations of objects with complex topology}},
url = {https://ieeexplore.ieee.org/document/8363742/},
year = {2018}
}

@article{Oliveira2018,
abstract = {Positron emission tomography (PET) neuroimaging with the Pittsburgh Compound{\_}B (PiB) is widely used to assess amyloid plaque burden. Standard quantification approaches normalize PiB-PET by mean cerebellar gray matter uptake. Previous studies suggested similar pons and white-matter uptake in Alzheimer's disease (AD) and healthy controls (HC), but lack exhaustive comparison of normalization across the three regions, with data-driven diagnostic classification. We aimed to compare the impact of distinct reference regions in normalization, measured by data-driven statistical analysis, and correlation with cerebrospinal fluid (CSF) amyloid $\beta$ (A$\beta$) species concentrations. 243 individuals with clinical diagnosis of AD, HC, mild cognitive impairment (MCI) and other dementias, from the Biomarkers for Alzheimer's/Parkinson's Disease (BIOMARKAPD) initiative were included. PiB-PET images and CSF concentrations of A$\beta$38, A$\beta$40 and A$\beta$42 were submitted to classification using support vector machines. Voxel-wise group differences and correlations between normalized PiB-PET images and CSF A$\beta$ concentrations were calculated. Normalization by cerebellar gray matter and pons yielded identical classification accuracy of AD (accuracy-96{\%}, sensitivity-96{\%}, specificity-95{\%}), and significantly higher than A$\beta$ concentrations (best accuracy 91{\%}). Normalization by the white-matter showed decreased extent of statistically significant multivoxel patterns and was the only method not outperforming CSF biomarkers, suggesting statistical inferiority. A$\beta$38 and A$\beta$40 correlated negatively with PiB-PET images normalized by the white-matter, corroborating previous observations of correlations with non-AD-specific subcortical changes in white-matter. In general, when using the pons as reference region, higher voxel-wise group differences and stronger correlation with A$\beta$42, the A$\beta$42/A$\beta$40 or A$\beta$42/A$\beta$38 ratios were found compared to normalization based on cerebellar gray matter.},
author = {Oliveira, Francisco and Leuzy, Antoine and Castelhano, Jo{\~{a}}o and Chiotis, Konstantinos and Hasselbalch, Steen Gregers and Rinne, Juha and Mendon{\c{c}}a, Alexandre and Otto, Markus and Lle{\'{o}}, Alberto and Santana, Isabel and Johansson, Jarkko and Anderl-Straub, Sarah and Arnim, Christine and Beer, Ambros and Blesa, Rafael and Fortea, Juan and Sanna-Kaisa, Herukka and Portelius, Erik and Pannee, Josef and Zetterberg, Henrik and Blennow, Kaj and Moreira, Ana P. and Abrunhosa, Antero and Nordberg, Agneta and Castelo-Branco, Miguel},
doi = {10.1016/j.nicl.2018.08.023},
file = {:Users/bpaniagua/Library/Application Support/Mendeley Desktop/Downloaded/Oliveira et al. - 2018 - Data driven diagnostic classification in Alzheimer's disease based on different reference regions for normaliz.pdf:pdf},
issn = {22131582},
journal = {NeuroImage: Clinical},
month = {jan},
pages = {603--610},
publisher = {Elsevier Inc.},
title = {{Data driven diagnostic classification in Alzheimer's disease based on different reference regions for normalization of PiB-PET images and correlation with CSF concentrations of A$\beta$ species}},
volume = {20},
year = {2018}
}
@article{Oliveira2018a,
abstract = {Background: Pittsburgh Compound B (PiB) positron emission tomography (PET) is used to visualize in vivo amyloid plaques in the brain. Frequently the PiB examinations are complemented with a fluorodeoxyglucose (FDG) PET scan to further assess neurodegeneration. Objective: Our goal is to identify alternative correlates of FDG images by assessing which kinetic methods originate PiB derived relative delivery ratio (R 1) images that can be correlated with the FDG images, and to compare them with PiB perfusion (pPiB) images obtained from the early-phase of PiB acquisition. Methods: We selected 52 patients with cognitive impairment who underwent a dynamic PiB and FDG acquisitions. To compute the R 1 images, two simplified reference tissue models (SRTM and SRTM2) and two multi-linear reference tissue models (MRTM and MRTM2) were used. The pPiB images were obtained in two different time intervals. Results: All six types of images were of good quality and highly correlated with the FDG images (mean voxelwise within-subjects r {\textgreater} 0.92). The higher correlation was found for FDG-R 1 (MRTM). Regarding the voxelwise regional correlation, the higher mean all brain correlations was r = 0.825 for FDG-R 1 (MRTM) and statistically significant in the whole brain analysis. Conclusion: All R 1 and pPiB images here tested have potential to assess the metabolic impact of neurodegeneration almost as reliably as the FDG images. However, this is not enough to validate these images for a single-subject analysis compared with the FDG image, and thus they cannot yet be used clinically to replace the FDG image before such evaluation.},
author = {Oliveira, Francisco P.M. and Moreira, Ana Paula and {De Mendon{\c{c}}a}, Alexandre and Verdelho, Ana and Xavier, Carolina and Barroca, Dalila and Rio, Joana and Cardoso, Eva and Cruz, {\^{A}}ngela and Abrunhosa, Antero and Castelo-Branco, Miguel},
doi = {10.3233/JAD-180274},
file = {:Users/bpaniagua/Library/Application Support/Mendeley Desktop/Downloaded/Oliveira et al. - 2018 - Can 11 C-PiB-PET relative delivery R 1 or 11 C-PiB-PET perfusion replace 18 F-FDG-PET in the assessment of brai.pdf:pdf},
issn = {18758908},
journal = {Journal of Alzheimer's Disease},
keywords = {11 C-PIB,18 F-FDG,Alzheimer's disease,compartmental models,neurodegeneration,perfusion},
number = {1},
pages = {89--97},
publisher = {IOS Press},
title = {{Can 11 C-PiB-PET relative delivery R 1 or 11 C-PiB-PET perfusion replace 18 F-FDG-PET in the assessment of brain neurodegeneration?}},
volume = {65},
year = {2018}
}
@article{Grothausmann2017,
abstract = {{\textless}p{\textgreater}Grothausmann R, Knudsen L, Ochs M, M{\"{u}}hlfeld C. Digital 3D reconstructions using histological serial sections of lung tissue including the alveolar capillary network. Am J Physiol Lung Cell Mol Physiol 312: L243–L257, 2017. First published December 2, 2016; doi: 10.1152/ajplung.00326.2016 .—The alveolar capillary network (ACN) provides an enormously large surface area that is necessary for pulmonary gas exchange. Changes of the ACN during normal or pathological development or in pulmonary diseases are of great functional impact and warrant further analysis. Due to the complexity of the three-dimensional (3D) architecture of the ACN, 2D approaches are limited in providing a comprehensive impression of the characteristics of the normal ACN or the nature of its alterations. Stereological methods offer a quantitative way to assess the ACN in 3D in terms of capillary volume, surface area, or number but lack a 3D visualization to interpret the data. Hence, the necessity to visualize the ACN in 3D and to correlate this with data from the same set of data arises. Such an approach requires a large sample volume combined with a high resolution. Here, we present a technically simple and cost-efficient approach to create 3D representations of lung tissue ranging from bronchioles over alveolar ducts and alveoli up to the ACN from more than 1 mm sample extent to a resolution of less than 1 $\mu$m. The method is based on automated image acquisition of serially sectioned epoxy resin-embedded lung tissue fixed by vascular perfusion and subsequent automated digital reconstruction and analysis of the 3D data. This efficient method may help to better understand mechanisms of vascular development and pathology of the lung.{\textless}/p{\textgreater}},
author = {Grothausmann, Roman and Knudsen, Lars and Ochs, Matthias and M{\"{u}}hlfeld, Christian},
doi = {10.1152/ajplung.00326.2016},
file = {:Users/bpaniagua/Library/Application Support/Mendeley Desktop/Downloaded/Grothausmann et al. - 2017 - Digital 3D reconstructions using histological serial sections of lung tissue including the alveolar capilla.pdf:pdf},
issn = {1040-0605},
journal = {American Journal of Physiology-Lung Cellular and Molecular Physiology},
month = {feb},
number = {2},
pages = {L243--L257},
title = {{Digital 3D reconstructions using histological serial sections of lung tissue including the alveolar capillary network}},
url = {https://www.physiology.org/doi/10.1152/ajplung.00326.2016},
volume = {312},
year = {2017}
}
@inproceedings{Grothausmann2018,
abstract = {Changes in lung volume during the breathing cycle and also lung diseases are likely to deform even the smallest airspace units, the alveoli. This study reports general ideas to investigate such changes with 3D digital image processing. It comprises morphological characterizations like volume and surface, an evaluation of the angle distribution between facets formed by the septal walls, the number of neighboring alveoli and a shape analysis of the alveolar airspace. The software used is open-source and custom programs are available at: http://github.com/romangrothausmann/.},
author = {Grothausmann, Roman and M{\"{u}}hlfeld, Christian and Ochs, Matthias and Knudsen, Lars},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-04747-4_5},
isbn = {9783030047467},
issn = {16113349},
pages = {49--64},
publisher = {Springer Verlag},
title = {{Shape and Facet Analyses of Alveolar Airspaces of the Lung}},
volume = {11167 LNCS},
year = {2018}
}
